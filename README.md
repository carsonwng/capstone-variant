# Common Crawl Parser
---
A set of scripts, tools, and more to extract domain-specific webpages in the common-crawl index.

*Common Crawl is an extremely large public dataset of webpages and websites provided for free. The estimated size of the Common Crawl dataset is rougly ~54.4 billion pages*
---
### Goals
By mid-jan, my goal was to have at least the parsing, and data extraction complete.

The change-in-scope and it's affect on my goals is in another md file found [here](./SCOPE.md). 